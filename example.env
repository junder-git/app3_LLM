# .env - High Performance Configuration for Open WebUI + Ollama

# Security
SECRET_KEY=your-very-secret-key-change-this-in-production-make-it-long-and-random

# PERFORMANCE OPTIMIZATIONS FOR 10-CORE/32GB/8GB VRAM SYSTEM
# Resource Limits - Optimized for 24B parameter models
OLLAMA_MEMORY_LIMIT=28G                    # Use 28GB of 32GB RAM
OLLAMA_MEMORY_RESERVATION=20G              # Reserve 20GB minimum

# GPU Configuration - RTX 3060 Ti Optimized
NVIDIA_VISIBLE_DEVICES=all
MAX_VRAM=7GB                               # Reserve 1GB VRAM for system overhead

# Open WebUI Configuration
ENABLE_SIGNUP=true
WEBUI_URL=https://ai.junder.uk

# Default Admin User
DEFAULT_USER_EMAIL=j@junder.uk
DEFAULT_USER_NAME=jai
DEFAULT_USER_PASSWORD=admin123

# STORAGE OPTIMIZATION
# Set to SSD path for better I/O performance (optional)
# OLLAMA_DATA_PATH=/path/to/fast/ssd/ollama_data

# ADVANCED PERFORMANCE SETTINGS
# Concurrent request handling
OLLAMA_NUM_PARALLEL=4                      # Handle 4 requests simultaneously
OLLAMA_MAX_LOADED_MODELS=1                 # Keep 1 model in memory
OLLAMA_MAX_QUEUE=20                        # Queue depth

# Model loading and retention
OLLAMA_KEEP_ALIVE=30m                      # Keep models loaded for 30 minutes
OLLAMA_LOAD_TIMEOUT=600                    # 10 minutes timeout for large models
OLLAMA_REQUEST_TIMEOUT=300                 # 5 minutes per request

# CPU Optimization
OMP_NUM_THREADS=10                         # Utilize all 10 CPU cores
GOMP_CPU_AFFINITY=0-9                      # Pin threads to all cores

# Memory Management
MALLOC_ARENA_MAX=2                         # Reduce memory fragmentation

# OLLAMA MODEL CONFIGURATION
# These will be set automatically when models are loaded
# OLLAMA_FLASH_ATTENTION=1                 # Enable if model supports it
# OLLAMA_CONTEXT_SIZE=4096                 # Adjust based on available VRAM

# Note: IP whitelisting is configured directly in nginx/nginx.conf