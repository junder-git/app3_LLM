version: '3.8'

services:
  nginx:
    image: nginx:alpine
    container_name: ai-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./static:/usr/share/nginx/html/static:ro
      - nginx_cache:/var/cache/nginx
    depends_on:
      - quart-app
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    restart: unless-stopped

  ollama:
    build:
      context: ./ollama
      dockerfile: Dockerfile
    container_name: ai-ollama
    volumes:
      - ollama_models:/root/.ollama/models
      - ./ollama/scripts:/scripts
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_HOST=0.0.0.0
    ports:
      - "11434:11434"
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 16G
        reservations:
          cpus: '1.0'
          memory: 8G
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    runtime: nvidia
    restart: unless-stopped

  quart-app:
    build:
      context: ./quart-app
      dockerfile: Dockerfile
    container_name: ai-quart-app
    environment:
      - REDIS_URL=redis://redis:6379/0
      - OLLAMA_URL=http://ollama:11434
      - SECRET_KEY=${SECRET_KEY:-your-secret-key-here}
    volumes:
      - ./quart-app:/app
    depends_on:
      - redis
      - ollama
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 8G
        reservations:
          cpus: '0.5'
          memory: 4G
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: ai-redis
    command: redis-server /usr/local/etc/redis/redis.conf
    volumes:
      - redis_data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    ports:
      - "6379:6379"
    networks:
      - ai-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 1G
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  ai-network:
    driver: bridge

volumes:
  nginx_cache:
  ollama_models:
  redis_data: